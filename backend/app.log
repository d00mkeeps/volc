2024-10-21 13:30:42,901 - app.core.llm_config - INFO - Getting LLM config for: default
2024-10-21 13:30:42,902 - app.core.llm_config - DEBUG - Config data: {'model': 'claude-3-5-sonnet-20240620', 'max_tokens': 250, 'temperature': 0.5, 'system_prompt': 'Default system prompt here'}
2024-10-21 13:30:42,903 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-10-21 13:30:42,903 - httpx - DEBUG - load_verify_locations cafile='/Users/mileshillary/Desktop/supreme-octo-doodle/.venv/lib/python3.12/site-packages/certifi/cacert.pem'
2024-10-21 13:30:42,914 - app.services.llm_service - INFO - LLMService initialized with config: model='claude-3-5-sonnet-20240620' max_tokens=250 temperature=0.5 system_prompt='Default system prompt here'
